# Comparing `tmp/pyfacer-0.0.3-py3-none-any.whl.zip` & `tmp/pyfacer-0.0.4-py3-none-any.whl.zip`

## zipinfo {}

```diff
@@ -1,30 +1,34 @@
-Zip file size: 33942 bytes, number of entries: 28
--rw-r--r--  2.0 unx     1675 b- defN 23-May-04 10:32 facer/__init__.py
--rw-r--r--  2.0 unx     7246 b- defN 23-May-04 10:46 facer/draw.py
--rw-r--r--  2.0 unx      545 b- defN 23-Apr-27 08:30 facer/io.py
--rw-r--r--  2.0 unx      962 b- defN 23-Apr-27 08:30 facer/show.py
--rw-r--r--  2.0 unx    13358 b- defN 23-Apr-28 02:01 facer/transform.py
--rw-r--r--  2.0 unx     5886 b- defN 23-May-04 10:53 facer/util.py
--rw-r--r--  2.0 unx       19 b- defN 23-May-05 03:11 facer/version.py
--rw-r--r--  2.0 unx       67 b- defN 23-May-04 07:21 facer/face_alignment/__init__.py
--rw-r--r--  2.0 unx      738 b- defN 23-Apr-28 03:30 facer/face_alignment/base.py
--rw-r--r--  2.0 unx     7113 b- defN 23-May-05 02:42 facer/face_alignment/farl.py
--rw-r--r--  2.0 unx     1470 b- defN 23-May-05 03:08 facer/face_alignment/network/__init__.py
--rw-r--r--  2.0 unx     2766 b- defN 23-May-04 07:34 facer/face_alignment/network/common.py
--rw-r--r--  2.0 unx     1374 b- defN 23-May-05 03:08 facer/face_alignment/network/geometry.py
--rw-r--r--  2.0 unx      907 b- defN 23-May-04 08:33 facer/face_alignment/network/mmseg.py
--rw-r--r--  2.0 unx     6315 b- defN 23-May-04 09:28 facer/face_alignment/network/transformers.py
--rw-r--r--  2.0 unx      102 b- defN 23-Apr-28 03:32 facer/face_alignment/network/farl/__init__.py
--rw-r--r--  2.0 unx    16648 b- defN 23-May-04 07:54 facer/face_alignment/network/farl/model.py
--rw-r--r--  2.0 unx       73 b- defN 23-Apr-27 08:30 facer/face_detection/__init__.py
--rw-r--r--  2.0 unx      372 b- defN 23-Apr-27 08:30 facer/face_detection/base.py
--rw-r--r--  2.0 unx    20655 b- defN 23-Apr-28 02:01 facer/face_detection/retinaface.py
--rw-r--r--  2.0 unx       61 b- defN 23-Apr-27 08:30 facer/face_parsing/__init__.py
--rw-r--r--  2.0 unx      732 b- defN 23-Apr-27 08:30 facer/face_parsing/base.py
--rw-r--r--  2.0 unx     4005 b- defN 23-Apr-28 02:01 facer/face_parsing/farl.py
--rwxr-xr-x  2.0 unx     1070 b- defN 23-May-05 03:30 pyfacer-0.0.3.dist-info/LICENSE
--rw-r--r--  2.0 unx     5174 b- defN 23-May-05 03:30 pyfacer-0.0.3.dist-info/METADATA
--rw-r--r--  2.0 unx       92 b- defN 23-May-05 03:30 pyfacer-0.0.3.dist-info/WHEEL
--rw-r--r--  2.0 unx        6 b- defN 23-May-05 03:30 pyfacer-0.0.3.dist-info/top_level.txt
-?rw-rw-r--  2.0 unx     2335 b- defN 23-May-05 03:30 pyfacer-0.0.3.dist-info/RECORD
-28 files, 101766 bytes uncompressed, 30172 bytes compressed:  70.4%
+Zip file size: 38633 bytes, number of entries: 32
+-rw-r--r--  2.0 unx     2077 b- defN 23-May-14 11:02 facer/__init__.py
+-rw-r--r--  2.0 unx     7246 b- defN 23-May-14 09:38 facer/draw.py
+-rw-r--r--  2.0 unx      545 b- defN 23-May-14 09:38 facer/io.py
+-rw-r--r--  2.0 unx      962 b- defN 23-May-14 09:38 facer/show.py
+-rw-r--r--  2.0 unx    13358 b- defN 23-May-14 10:58 facer/transform.py
+-rw-r--r--  2.0 unx     6021 b- defN 23-May-14 11:35 facer/util.py
+-rw-r--r--  2.0 unx       19 b- defN 23-May-14 12:53 facer/version.py
+-rw-r--r--  2.0 unx       67 b- defN 23-May-14 09:38 facer/face_alignment/__init__.py
+-rw-r--r--  2.0 unx      607 b- defN 23-May-14 12:42 facer/face_alignment/base.py
+-rw-r--r--  2.0 unx     7113 b- defN 23-May-14 09:38 facer/face_alignment/farl.py
+-rw-r--r--  2.0 unx     1470 b- defN 23-May-14 09:38 facer/face_alignment/network/__init__.py
+-rw-r--r--  2.0 unx     2766 b- defN 23-May-14 09:38 facer/face_alignment/network/common.py
+-rw-r--r--  2.0 unx     1374 b- defN 23-May-14 09:38 facer/face_alignment/network/geometry.py
+-rw-r--r--  2.0 unx      907 b- defN 23-May-14 09:38 facer/face_alignment/network/mmseg.py
+-rw-r--r--  2.0 unx     6317 b- defN 23-May-14 10:16 facer/face_alignment/network/transformers.py
+-rw-r--r--  2.0 unx       67 b- defN 23-May-14 11:10 facer/face_attribute/__init__.py
+-rw-r--r--  2.0 unx      679 b- defN 23-May-14 12:41 facer/face_attribute/base.py
+-rw-r--r--  2.0 unx     4761 b- defN 23-May-14 12:44 facer/face_attribute/farl.py
+-rw-r--r--  2.0 unx       73 b- defN 23-May-14 09:38 facer/face_detection/__init__.py
+-rw-r--r--  2.0 unx      372 b- defN 23-May-14 09:38 facer/face_detection/base.py
+-rw-r--r--  2.0 unx    20655 b- defN 23-May-14 09:38 facer/face_detection/retinaface.py
+-rw-r--r--  2.0 unx       61 b- defN 23-May-14 09:38 facer/face_parsing/__init__.py
+-rw-r--r--  2.0 unx      732 b- defN 23-May-14 09:38 facer/face_parsing/base.py
+-rw-r--r--  2.0 unx     4005 b- defN 23-May-14 09:38 facer/face_parsing/farl.py
+-rw-r--r--  2.0 unx      169 b- defN 23-May-14 12:45 facer/farl/__init__.py
+-rw-r--r--  2.0 unx     4801 b- defN 23-May-14 12:45 facer/farl/classification.py
+-rw-r--r--  2.0 unx    16648 b- defN 23-May-14 09:38 facer/farl/model.py
+-rwxr-xr-x  2.0 unx     1070 b- defN 23-May-14 12:53 pyfacer-0.0.4.dist-info/LICENSE
+-rw-r--r--  2.0 unx     6924 b- defN 23-May-14 12:53 pyfacer-0.0.4.dist-info/METADATA
+-rw-r--r--  2.0 unx       92 b- defN 23-May-14 12:53 pyfacer-0.0.4.dist-info/WHEEL
+-rw-r--r--  2.0 unx        6 b- defN 23-May-14 12:53 pyfacer-0.0.4.dist-info/top_level.txt
+?rw-rw-r--  2.0 unx     2630 b- defN 23-May-14 12:53 pyfacer-0.0.4.dist-info/RECORD
+32 files, 114594 bytes uncompressed, 34419 bytes compressed:  70.0%
```

## zipnote {}

```diff
@@ -39,18 +39,21 @@
 
 Filename: facer/face_alignment/network/mmseg.py
 Comment: 
 
 Filename: facer/face_alignment/network/transformers.py
 Comment: 
 
-Filename: facer/face_alignment/network/farl/__init__.py
+Filename: facer/face_attribute/__init__.py
 Comment: 
 
-Filename: facer/face_alignment/network/farl/model.py
+Filename: facer/face_attribute/base.py
+Comment: 
+
+Filename: facer/face_attribute/farl.py
 Comment: 
 
 Filename: facer/face_detection/__init__.py
 Comment: 
 
 Filename: facer/face_detection/base.py
 Comment: 
@@ -63,23 +66,32 @@
 
 Filename: facer/face_parsing/base.py
 Comment: 
 
 Filename: facer/face_parsing/farl.py
 Comment: 
 
-Filename: pyfacer-0.0.3.dist-info/LICENSE
+Filename: facer/farl/__init__.py
+Comment: 
+
+Filename: facer/farl/classification.py
+Comment: 
+
+Filename: facer/farl/model.py
+Comment: 
+
+Filename: pyfacer-0.0.4.dist-info/LICENSE
 Comment: 
 
-Filename: pyfacer-0.0.3.dist-info/METADATA
+Filename: pyfacer-0.0.4.dist-info/METADATA
 Comment: 
 
-Filename: pyfacer-0.0.3.dist-info/WHEEL
+Filename: pyfacer-0.0.4.dist-info/WHEEL
 Comment: 
 
-Filename: pyfacer-0.0.3.dist-info/top_level.txt
+Filename: pyfacer-0.0.4.dist-info/top_level.txt
 Comment: 
 
-Filename: pyfacer-0.0.3.dist-info/RECORD
+Filename: pyfacer-0.0.4.dist-info/RECORD
 Comment: 
 
 Zip file comment:
```

## facer/__init__.py

```diff
@@ -5,14 +5,15 @@
 from .util import hwc2bchw, bchw2hwc, bchw2bhwc, bhwc2bchw, bhwc2hwc
 from .draw import draw_bchw, draw_landmarks
 from .show import show_bchw, show_bhw
 
 from .face_detection import FaceDetector
 from .face_parsing import FaceParser
 from .face_alignment import FaceAlignment
+from .face_attribute import FaceAttribute
 
 
 def _split_name(name: str) -> Tuple[str, Optional[str]]:
     if '/' in name:
         detector_type, conf_name = name.split('/', 1)
     else:
         detector_type, conf_name = name, None
@@ -39,8 +40,16 @@
 
 def face_aligner(name: str, device: torch.device, **kwargs) -> FaceAlignment:
     aligner_type, conf_name = _split_name(name)
     if aligner_type == 'farl':
         from .face_alignment import FaRLFaceAlignment
         return FaRLFaceAlignment(conf_name, device=device, **kwargs).to(device)
     else:
-        raise RuntimeError(f'Unknown aligner type: {aligner_type}')
+        raise RuntimeError(f'Unknown aligner type: {aligner_type}')
+
+def face_attr(name: str, device: torch.device, **kwargs) -> FaceAttribute:
+    attr_type, conf_name = _split_name(name)
+    if attr_type == 'farl':
+        from .face_attribute import FaRLFaceAttribute
+        return FaRLFaceAttribute(conf_name, device=device, **kwargs).to(device)
+    else:
+        raise RuntimeError(f'Unknown attribute type: {attr_type}')
```

## facer/util.py

```diff
@@ -119,15 +119,15 @@
     elif isinstance(data, (list, tuple)):
         return [select_data(selection, val) for val in data]
     elif isinstance(data, torch.Tensor):
         return data[selection]
     return data
 
 
-def download_jit(url_or_paths: Union[str, List[str]], model_dir=None, map_location=None, **kwargs):
+def download_jit(url_or_paths: Union[str, List[str]], model_dir=None, map_location=None, jit=True, **kwargs):
     if isinstance(url_or_paths, str):
         url_or_paths = [url_or_paths]
 
     for url_or_path in url_or_paths:
         try:
             if validators.url(url_or_path):
                 url = url_or_path
@@ -154,14 +154,16 @@
                 cached_file = os.path.join(model_dir, filename)
                 if not os.path.exists(cached_file):
                     sys.stderr.write(
                         'Downloading: "{}" to {}\n'.format(url, cached_file))
                     download_url_to_file(url, cached_file)
             else:
                 cached_file = url_or_path
-
-            return torch.jit.load(cached_file, map_location=map_location, **kwargs)
+            if jit:
+                return torch.jit.load(cached_file, map_location=map_location, **kwargs)
+            else:
+                return torch.load(cached_file, map_location=map_location, **kwargs)
         except:
             sys.stderr.write(f'failed downloading from {url_or_path}\n')
             raise
 
     raise RuntimeError('failed to download jit models from all given urls')
```

## facer/version.py

```diff
@@ -1 +1 @@
-__version__="0.0.3"
+__version__="0.0.4"
```

## facer/face_alignment/base.py

```diff
@@ -15,13 +15,10 @@
 
     Returns:
         data (Dict[str, Any]):
 
             * image_ids (torch.Tensor): nfaces
             * rects (torch.Tensor): nfaces x 4 (x1, y1, x2, y2)
             * points (torch.Tensor): nfaces x 5 x 2 (x, y)
-            * seg (Dict[str, Any]):
-
-                * logits (torch.Tensor): nfaces x nclasses x h x w
-                * label_names (List[str]): nclasses
+            * alignment 
     """
     pass
```

## facer/face_alignment/network/transformers.py

```diff
@@ -6,15 +6,15 @@
 from typing import Optional, List, Tuple
 
 import torch
 import torch.nn as nn
 import torch.nn.functional as F
 
 
-from . import farl
+from ... import farl
 
 
 def _make_fpns(vision_patch_size: int, output_channels: int):
     if vision_patch_size in {16, 14}:
         fpn1 = nn.Sequential(
             nn.ConvTranspose2d(output_channels, output_channels,
                                kernel_size=2, stride=2),
```

## Comparing `facer/face_alignment/network/farl/model.py` & `facer/farl/model.py`

 * *Files identical despite different names*

## Comparing `pyfacer-0.0.3.dist-info/LICENSE` & `pyfacer-0.0.4.dist-info/LICENSE`

 * *Files identical despite different names*

## Comparing `pyfacer-0.0.3.dist-info/METADATA` & `pyfacer-0.0.4.dist-info/METADATA`

 * *Files 18% similar despite different names*

```diff
@@ -1,10 +1,10 @@
 Metadata-Version: 2.1
 Name: pyfacer
-Version: 0.0.3
+Version: 0.0.4
 Summary: Face related toolkit
 Home-page: https://github.com/FacePerceiver/facer
 Author: FacePerceiver
 License: MIT
 Project-URL: Documentation, https://github.com/FacePerceiver/facer
 Project-URL: Source, https://github.com/FacePerceiver/facer
 Project-URL: Tracker, https://github.com/FacePerceiver/facer/issues
@@ -23,26 +23,33 @@
 Requires-Dist: opencv-python
 
 # FACER
 
 Face related toolkit. This repo is still under construction to include more models.
 
 ## Updates
+- [14/05/2023] Face attribute recognition model trained on CelebA is available, check it out [here](./samples/face_attribute.ipynb).
 - [04/05/2023] Face alignment model trained on IBUG300W, AFLW19, WFLW dataset is available, check it out [here](./samples/face_alignment.ipynb).
 - [27/04/2023] Face parsing model trained on CelebM dataset is available, check it out [here](./samples/face_parsing.ipynb).
 
 ## Install
 
 The easiest way to install it is using pip:
 
 ```bash
 pip install git+https://github.com/FacePerceiver/facer.git@main
 ```
 No extra setup needs, pretrained weights will be downloaded automatically.
 
+If you have trouble install from source, you can try install from PyPI:
+```bash
+pip install pyfacer
+```
+the PyPI version is not guaranteed to be the latest version, but we will try to keep it up to date.
+
 
 ## Face Detection
 
 We simply wrap a retinaface detector for easy usage.
 ```python
 import facer
 
@@ -74,16 +81,15 @@
 We wrap the [FaRL](https://github.com/faceperceiver/farl) models for face parsing.
 ```python
 import torch
 import facer
 
 device = 'cuda' if torch.cuda.is_available() else 'cpu'
 
-image = facer.hwc2bchw(facer.read_hwc('data/twogirls.jpg')
-                       ).to(device=device)  # image: 1 x 3 x h x w
+image = facer.hwc2bchw(facer.read_hwc('data/twogirls.jpg')).to(device=device)  # image: 1 x 3 x h x w
 
 face_detector = facer.face_detector('retinaface/mobilenet', device=device)
 with torch.inference_mode():
     faces = face_detector(image)
 
 face_parser = facer.face_parser('farl/lapa/448', device=device) # optional "farl/celebm/448"
 
@@ -150,11 +156,55 @@
 
 Please consider citing
 ```
 @inproceedings{zheng2022farl,
   title={General facial representation learning in a visual-linguistic manner},
   author={Zheng, Yinglin and Yang, Hao and Zhang, Ting and Bao, Jianmin and Chen, Dongdong and Huang, Yangyu and Yuan, Lu and Chen, Dong and Zeng, Ming and Wen, Fang},
   booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
+  pages={18697--18709},
+  year={2022}
+}
+``` 
+
+## Face Attribute Recognition
+We wrap the [FaRL](https://github.com/faceperceiver/farl) models for face attribute recognition, the model achieves 92.06% accuracy on [CelebA](https://mmlab.ie.cuhk.edu.hk/projects/CelebA.html) dataset.
+
+```python
+import sys
+import torch
+import facer
+
+device = "cuda" if torch.cuda.is_available() else "cpu"
+
+# image: 1 x 3 x h x w
+image = facer.hwc2bchw(facer.read_hwc("data/girl.jpg")).to(device=device)
+
+face_detector = facer.face_detector("retinaface/mobilenet", device=device)
+with torch.inference_mode():
+    faces = face_detector(image)
+
+face_attr = facer.face_attr("farl/celeba/224", device=device)
+with torch.inference_mode():
+    faces = face_attr(image, faces)
+
+labels = face_attr.labels
+face1_attrs = faces["attrs"][0] # get the first face's attributes
+
+print(labels)
+
+for prob, label in zip(face1_attrs, labels):
+    if prob > 0.5:
+        print(label, prob.item())
+```
+
+Check [this notebook](./samples/face_attribute.ipynb) for full example.
+
+Please consider citing
+```
+@inproceedings{zheng2022farl,
+  title={General facial representation learning in a visual-linguistic manner},
+  author={Zheng, Yinglin and Yang, Hao and Zhang, Ting and Bao, Jianmin and Chen, Dongdong and Huang, Yangyu and Yuan, Lu and Chen, Dong and Zeng, Ming and Wen, Fang},
+  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
   pages={18697--18709},
   year={2022}
 }
 ```
```

## Comparing `pyfacer-0.0.3.dist-info/RECORD` & `pyfacer-0.0.4.dist-info/RECORD`

 * *Files 11% similar despite different names*

```diff
@@ -1,28 +1,32 @@
-facer/__init__.py,sha256=oz9_9tH_4ZcQowkMVDLwjrm7DxIxgOFGcHKMOF82uLA,1675
+facer/__init__.py,sha256=vZBwy6pA21Ej1-SIYi55jNN19BXAhCHmCfqTVEMhR5Y,2077
 facer/draw.py,sha256=vevNSN_wLXJG5wHzwwOzadsN-mq6DMdj3SxbKqkTkxM,7246
 facer/io.py,sha256=ynBWXy7illsGt1FtTOjZlqBW3Mv2IHrsbpmj32f3SiQ,545
 facer/show.py,sha256=jQEyk02d4gXfTsSDotzCGru5c3JmbMhzVAMSLBBlwww,962
 facer/transform.py,sha256=XHsqDdzItSJk7WekOmwNAH0D3BPz48ids6wltcvh9Pg,13358
-facer/util.py,sha256=57PR1TDx_3w8JUMa72QrowQNK-lwtjEIc-ZckRmGSWM,5886
-facer/version.py,sha256=qHUqGJ1ETm11miieM-ePA1QGMQj4nWOr9giOoUt1H_A,19
+facer/util.py,sha256=b0iwQFenp8QnL4A-mOlsIM7rlED6pDujrgNNySsXBRg,6021
+facer/version.py,sha256=m4-niQQxkfUYem6ZCVVW7XcMpv_ctPDXThIJGGnfT-o,19
 facer/face_alignment/__init__.py,sha256=DC1rYgBySHHD6FUCRKqWubyusox3lCWXVsuGdiNxFC4,67
-facer/face_alignment/base.py,sha256=d3lWu3deKWvIDChdl3GUQp4k8UiDyk6CxthCT-ypirQ,738
+facer/face_alignment/base.py,sha256=KMHoze67QoGr7HZBfMIZYpgpplQ1PXbQXa_lkAvAfjY,607
 facer/face_alignment/farl.py,sha256=9cHKd4yIolw321p2kUFuKIAGKuj_E3obUri3vEX6pGQ,7113
 facer/face_alignment/network/__init__.py,sha256=ZrCsKOA3jTH9KVK0fJAOt3wCDT0Sxf1fEVH_-FMs2gg,1470
 facer/face_alignment/network/common.py,sha256=qiAtPYTH5eJMian_hiptf0naEiLNySctZblt4w2E-gM,2766
 facer/face_alignment/network/geometry.py,sha256=UhfbTHNM8K7-qESLlqTLE30QR8p6LWUPSoiOe90bg_M,1374
 facer/face_alignment/network/mmseg.py,sha256=G5eHnIamwApCidTAkXxFCF836EDSy0Iuh9D5JCAMZFM,907
-facer/face_alignment/network/transformers.py,sha256=bTiZvnqfckBRq33lFUsKbcg6LRoUgcIKZMMZEcZDj1A,6315
-facer/face_alignment/network/farl/__init__.py,sha256=MGKCdqBTL6OGKiS_b9ki8DTIA2zrM1p5DiFBPRnufFQ,102
-facer/face_alignment/network/farl/model.py,sha256=ZKp86to4p072a9N6XoATlI5BX7HjRjK8hM3KbAsIgZM,16648
+facer/face_alignment/network/transformers.py,sha256=1YEyTBks3okId4tR8MHiYdrd7PyQ1EFfdj2YZYuYc5I,6317
+facer/face_attribute/__init__.py,sha256=PsAH6blboEqSQ85gRyeaflHe7rZryVWCwrFtC-f82zM,67
+facer/face_attribute/base.py,sha256=Y3J_GtMxgAASFpqncZIiRwNeUPQtK8WV8U4P7RVrKE4,679
+facer/face_attribute/farl.py,sha256=4VDxUQpcgTR3HfVNZs4vuBhgkzXF3MQBVeBFFA0nSeY,4761
 facer/face_detection/__init__.py,sha256=-uAQLsGBNY5fSilVYP6L3yg-fiS1FDUsJ9ltNKgGuQk,73
 facer/face_detection/base.py,sha256=ZQ55sccDDWLumxVWckAd8TjbUrcp9Q6eEEeW_eNNe6s,372
 facer/face_detection/retinaface.py,sha256=wmWlvFbfu_tlDJ033fMOoL_V_TVsTC6IlFTphgJwXHo,20655
 facer/face_parsing/__init__.py,sha256=TD6HvN1k_j-ea3ZqAK2ujHNZ9k-IT86Tm8iR4JnQh-g,61
 facer/face_parsing/base.py,sha256=NHp7zeZti5ziY6SCT1mOr3487P1PbsFLylQVwyftLaQ,732
 facer/face_parsing/farl.py,sha256=at7mRywm7JZZV1sHBBCe6GbEcbizbft5W1fZ1h5LceM,4005
-pyfacer-0.0.3.dist-info/LICENSE,sha256=41wcG5Hc62rg00AreChhWrFQeBz-st-PWTs8WZZRzbw,1070
-pyfacer-0.0.3.dist-info/METADATA,sha256=mZLErv6CiGREyU7Rd57CSEoJ3ganGBoiAIuULSXGLV4,5174
-pyfacer-0.0.3.dist-info/WHEEL,sha256=2wepM1nk4DS4eFpYrW1TTqPcoGNfHhhO_i5m4cOimbo,92
-pyfacer-0.0.3.dist-info/top_level.txt,sha256=RI7cxPXuElyMHhoF-mhdJT0bHMvEGJc01hNFzhUY-78,6
-pyfacer-0.0.3.dist-info/RECORD,,
+facer/farl/__init__.py,sha256=AoB3QWME-2ZgZNE2mwICeIXpQ4N0fRg03bRhEWb7r4U,169
+facer/farl/classification.py,sha256=A1Fk5bxf9D0fPRssgIMqJMUCGJhv17UkeMJT35v-aQI,4801
+facer/farl/model.py,sha256=ZKp86to4p072a9N6XoATlI5BX7HjRjK8hM3KbAsIgZM,16648
+pyfacer-0.0.4.dist-info/LICENSE,sha256=41wcG5Hc62rg00AreChhWrFQeBz-st-PWTs8WZZRzbw,1070
+pyfacer-0.0.4.dist-info/METADATA,sha256=yO4hRhKqOMA1oP_TpmukE0KMiDsco86zAKh02y9R6qo,6924
+pyfacer-0.0.4.dist-info/WHEEL,sha256=2wepM1nk4DS4eFpYrW1TTqPcoGNfHhhO_i5m4cOimbo,92
+pyfacer-0.0.4.dist-info/top_level.txt,sha256=RI7cxPXuElyMHhoF-mhdJT0bHMvEGJc01hNFzhUY-78,6
+pyfacer-0.0.4.dist-info/RECORD,,
```

